# Fix Unix/Windows Line Ending Handling in Markdown Renderer

**Date:** 2025-01-06
**Issue:** The markdown renderer does not correctly handle mixed or Windows line endings (\r\n), causing potential rendering artifacts.

## Problem Analysis

### Current Behavior

The codebase has multiple locations that split text on `'\n'` characters without considering Windows-style `\r\n` line endings:

1. **`src/markdown_renderer.rs:459`** - Paragraph rendering
   ```rust
   InlineSpan::Text(t) if t.contains('\n') => {
       let parts: Vec<&str> = t.split('\n').collect();
   ```

2. **`src/markdown_renderer.rs:1752`** - List item rendering
   ```rust
   InlineSpan::Text(t) if t.contains('\n') => {
       let parts: Vec<&str> = t.split('\n').collect();
   ```

### The Issue

When a markdown file has Windows line endings (`\r\n`), the following occurs:

1. File is read with `std::fs::read_to_string` which preserves line endings as-is
2. `pulldown-cmark` parser processes the text and emits `Event::Text` with raw content including `\r` characters
3. Text like `"Line 1\r\nLine 2"` is split on `'\n'` only
4. Result: `["Line 1\r", "Line 2"]` - the `\r` character remains!
5. The carriage return (`\r`) is a control character that can cause text rendering issues in GUI applications

### Why This Matters

- **Windows users**: Most text editors on Windows create files with `\r\n` line endings by default
- **Cross-platform compatibility**: Files may have mixed line endings (some lines with `\n`, some with `\r\n`)
- **Display artifacts**: The `\r` character can cause text to overwrite itself or display incorrectly
- **Whitespace issues**: The `\r` at the end of text spans may interfere with text measurement and layout

### Confirmed Locations

Using grep, I found these problematic patterns:
- `markdown_renderer.rs:459` - `t.split('\n')` in paragraph handling
- `markdown_renderer.rs:1752` - `t.split('\n')` in list item handling
- Code block handling at line 1859 already handles this correctly: `text.replace(['\n', '\r'], "")`

## Proposed Solution

### Option 1: Normalize at File Load Time (Recommended)

**Pros:**
- Single point of normalization
- Ensures all downstream code works with consistent line endings
- Simpler to reason about
- Performance: normalization happens once per file load

**Cons:**
- Slightly more memory allocation during load
- Loses original line ending information (not relevant for this use case)

**Implementation:**
In `src/app.rs`, modify `read_file_lossy()`:

```rust
fn read_file_lossy(path: &Path) -> Result<(String, bool)> {
    match std::fs::read_to_string(path) {
        Ok(s) => Ok((normalize_line_endings(&s), false)),
        Err(e) if e.kind() == ErrorKind::InvalidData => {
            let bytes = std::fs::read(path)?;
            let s = String::from_utf8_lossy(&bytes).into_owned();
            Ok((normalize_line_endings(&s), true))
        }
        Err(e) => Err(e.into()),
    }
}

fn normalize_line_endings(s: &str) -> String {
    s.replace("\r\n", "\n").replace('\r', "\n")
}
```

**Why this order matters:**
1. First replace `\r\n` with `\n` (Windows → Unix)
2. Then replace any remaining `\r` with `\n` (old Mac → Unix)
3. This handles all three line ending styles correctly

### Option 2: Fix at Split Points

**Pros:**
- Preserves original file content exactly
- More localized changes

**Cons:**
- Multiple places to fix (at least 2 confirmed, possibly more)
- Easy to miss locations in future code
- Slightly less efficient (processing line endings multiple times)

**Implementation:**
Create a helper function in `markdown_renderer.rs`:

```rust
/// Split text on any line ending pattern (\n, \r\n, or \r)
fn split_lines(text: &str) -> Vec<&str> {
    text.split('\n')
        .flat_map(|s| s.split('\r'))
        .collect()
}
```

Then replace all `t.split('\n')` calls with `split_lines(&t)`.

**Problem with this approach:** The `flat_map` might create extra empty strings that need filtering.

Better implementation:
```rust
fn split_lines(text: &str) -> Vec<String> {
    text.lines().map(|s| s.to_string()).collect()
}
```

**Problem:** `.lines()` strips the line ending but doesn't give us the empty lines between blank lines in the same way.

**Best implementation for Option 2:**
```rust
/// Split text on line boundaries, handling \r\n, \n, and \r
fn split_on_line_endings(text: &str) -> Vec<&str> {
    // First normalize \r\n to \n, then split on remaining \r or \n
    // This is tricky without allocation, so just strip \r first
    let cleaned = text.replace('\r', "");
    cleaned.split('\n').collect()
}
```

**Problem:** This requires allocation and returns references to temporary string.

## Recommendation

**Use Option 1: Normalize at File Load Time**

This is the cleanest solution because:
1. Single point of normalization - easier to understand and maintain
2. All downstream code works with consistent input
3. Better performance - normalization happens once
4. Simpler implementation - just two `.replace()` calls
5. No risk of missing edge cases in rendering code

## Implementation Plan

### Phase 1: Add Normalization Function ✓

1. Add `normalize_line_endings()` helper function to `src/app.rs`:
   ```rust
   /// Normalize all line endings to Unix style (\n)
   /// Handles Windows (\r\n), Unix (\n), and old Mac (\r) formats
   fn normalize_line_endings(s: &str) -> String {
       // Order matters: replace \r\n first, then remaining \r
       s.replace("\r\n", "\n").replace('\r', "\n")
   }
   ```

2. Add unit tests for the normalization function:
   ```rust
   #[test]
   fn test_normalize_line_endings() {
       // Windows style
       assert_eq!(normalize_line_endings("Hello\r\nWorld"), "Hello\nWorld");

       // Unix style (no change)
       assert_eq!(normalize_line_endings("Hello\nWorld"), "Hello\nWorld");

       // Old Mac style
       assert_eq!(normalize_line_endings("Hello\rWorld"), "Hello\nWorld");

       // Mixed
       assert_eq!(normalize_line_endings("A\r\nB\nC\rD"), "A\nB\nC\nD");

       // Multiple blank lines
       assert_eq!(normalize_line_endings("A\r\n\r\nB"), "A\n\nB");
   }
   ```

### Phase 2: Apply Normalization ✓

1. Modify `read_file_lossy()` in `src/app.rs` to call normalization
2. Modify `load_content()` in `src/app.rs` to normalize sample content too (in case samples have CRLF)

### Phase 3: Testing ✓

1. Create test file with Windows line endings (`test_windows_endings.md`)
2. Create test file with Unix line endings (`test_unix_endings.md`)
3. Create test file with mixed line endings (`test_mixed_endings.md`)
4. Test all three files in the application:
   - Verify paragraphs render correctly
   - Verify list items render correctly
   - Verify code blocks render correctly
   - Verify tables render correctly
5. Run existing test suite: `cargo test`
6. Manual UI testing with the test files

### Phase 4: Documentation ✓

1. Add comment to `read_file_lossy()` explaining line ending normalization
2. Update CLAUDE.md to document this behavior under "File Operations" section
3. Add note in README.md if relevant (probably not needed for user-facing docs)

### Phase 5: Cleanup ✓

1. Remove test markdown files created for testing
2. Verify no warnings from `cargo clippy`
3. Ensure `cargo fmt` is clean

## Testing Strategy

### Unit Tests

```rust
#[test]
fn test_load_file_with_windows_line_endings() -> Result<()> {
    let mut app = MarkdownViewerApp::new();
    let mut temp_file = NamedTempFile::new()?;

    // Write content with explicit \r\n
    temp_file.write_all(b"Line 1\r\nLine 2\r\n\r\nParagraph")?;
    temp_file.flush()?;

    app.load_file(temp_file.path().to_path_buf())?;

    // Should not contain any \r characters
    assert!(!app.current_content.contains('\r'));
    assert!(app.current_content.contains("Line 1\nLine 2"));
    Ok(())
}

#[test]
fn test_load_file_with_mixed_line_endings() -> Result<()> {
    let mut app = MarkdownViewerApp::new();
    let mut temp_file = NamedTempFile::new()?;

    // Mix of \r\n, \n, and \r
    temp_file.write_all(b"Line 1\r\nLine 2\nLine 3\rLine 4")?;
    temp_file.flush()?;

    app.load_file(temp_file.path().to_path_buf())?;

    // All should be normalized to \n
    assert!(!app.current_content.contains('\r'));
    assert_eq!(app.current_content.lines().count(), 4);
    Ok(())
}
```

### Integration Tests

1. Load test files in the viewer manually
2. Check for visual artifacts in:
   - Paragraph text
   - List items (bulleted and numbered)
   - Table cells
   - Code blocks (already handles this correctly)
   - Blockquotes

## Alternative Considered: Upstream Fix

We could report this to the `pulldown-cmark` project, but:
1. It's unclear if this is a bug or expected behavior
2. They may consider line ending normalization to be the application's responsibility
3. Fixing it in our code gives us immediate control
4. The fix is simple and has minimal performance impact

## Risk Assessment

**Low Risk** - This change:
- Only affects file loading
- Is a pure string transformation
- Won't break existing functionality
- Has no external dependencies
- Can be thoroughly tested with unit tests

## Performance Impact

**Negligible** - The normalization:
- Happens once per file load
- Uses standard library `.replace()` which is optimized
- For a 1MB markdown file, the overhead is <1ms
- No impact on rendering performance

## Backward Compatibility

**Fully Compatible** - This change:
- Doesn't alter any public APIs
- Doesn't change file save behavior
- Only normalizes internal representation
- Users won't notice any difference except better rendering

## Success Criteria

- [ ] All test files (Windows/Unix/Mixed endings) render identically
- [ ] No `\r` characters in parsed content after file load
- [ ] All existing tests pass
- [ ] No rendering artifacts in UI with any line ending style
- [ ] `cargo clippy` reports no warnings
- [ ] Code is properly documented
